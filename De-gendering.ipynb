{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De-gending text\n",
    "\n",
    "Steps:\n",
    "1. Load data for each different corpus into consistent format\n",
    "    - Enron\n",
    "    - X RtGender\n",
    "2. X Train-Dev-Test Split on all of them\n",
    "3. X Build TF-IDF vectorizors on all training datasets\n",
    "4. X Build gender classifiers on all training datasets\n",
    "5. Use a count-vectorizer to build the Delete Procedure\n",
    "    - One vectorizer for each (male/female)\n",
    "    - Use this to create a dict mapping each word to its count value\n",
    "    - Lambda = 1; gamma = 5 (to start)\n",
    "    - Then use a function to look up the count ratio for each word given a sentence\n",
    "6. Make a similarity function - TF-IDF weighted word overlap between sentences.\n",
    "    - Maybe pairwise pre-compute this for all combos?\n",
    "7. Make Retrieve functions\n",
    "    - First one that retrieves the most similar sentence in the target attribute\n",
    "    - Next one that gets the top few sentences, and replaces the attributes in the source sentence one at a time with attributes in the target sentence(s)\n",
    "    \n",
    "Experiments:\n",
    "1. Do each of these individually, end-to-end\n",
    "2. Do each combination of applying different de-gendering systems to each other dataset. Apply the datasets trained gender classifier, and look at drop in acc, F1, and change in confusion matrix vs. before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "from dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "Cleaning data...\n",
      "Making data splits...\n",
      "Training the vectorizer...\n",
      "Transforming the vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Documents\\School\\Fall 2018\\independent_study\\dataset.py:133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.splits.test['label_col'] = test_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a base classifier...\n",
      "Done initializing fitocracy_responses dataset!\n"
     ]
    }
   ],
   "source": [
    "PATH = 'data/rt_gender/'\n",
    "fitocracy = Dataset('fitocracy_responses', PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- X Get the counts for each word (naive-bayes counts)\n",
    "    - Transform into logspace\n",
    "- Set a gamma threshold\n",
    "- For each sentence, split into context, attributes by this threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████▎                  | 97587/130623 [03:50<01:05, 505.51it/s]"
     ]
    }
   ],
   "source": [
    "from dataset import TransformedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_dataset = TransformedDataset(fitocracy, 2, 1, wc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred = fitocracy.clf.predict(fitocracy.vecs.train)\n",
    "dev_pred = fitocracy.clf.predict(fitocracy.vecs.dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.77      0.70    124204\n",
      "          1       0.73      0.58      0.65    130623\n",
      "\n",
      "avg / total       0.69      0.68      0.67    254827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(fitocracy.labels.train, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.76      0.69     15518\n",
      "          1       0.72      0.58      0.64     16336\n",
      "\n",
      "avg / total       0.68      0.67      0.67     31854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(fitocracy.labels.dev, dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building the count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambd = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split male/female\n",
    "male_df = fitocracy.df[fitocracy.df['responder_gender'] == 'M']\n",
    "female_df = fitocracy.df[fitocracy.df['responder_gender'] == 'W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_count_vectorizer = CountVectorizer(min_df=10).fit(male_df['response_text'])\n",
    "female_count_vectorizer = CountVectorizer(min_df=10).fit(female_df['response_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_word_counts = np.array(male_count_vectorizer.transform(\n",
    "    [' '.join(male_df['response_text'])]).todense())[0]\n",
    "f_word_counts = np.array(female_count_vectorizer.transform(\n",
    "    [' '.join(female_df['response_text'])]).todense())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_features = male_count_vectorizer.get_feature_names()\n",
    "f_features = female_count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df = pd.DataFrame(f_word_counts, index=f_features, columns=['female_count'])\n",
    "m_df = pd.DataFrame(m_word_counts, index=m_features, columns=['male_count'])\n",
    "full_df = pd.concat([f_df, m_df], axis=1)\n",
    "full_df.fillna(0, inplace=True)\n",
    "full_df['female_ratio'] = ((full_df['female_count'] + lambd) /\n",
    "                    (full_df['male_count'] + lambd))\n",
    "full_df['male_ratio'] = ((full_df['male_count'] + lambd) /\n",
    "                    (full_df['female_count'] + lambd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_set = set(full_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining which words to replace\n",
    "\n",
    "Given a sentence score each word, and if it is above gamma in favor of the current gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamma = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_words(row):\n",
    "    text = row['response_text']\n",
    "    gender = row['responder_gender']\n",
    "    gender_col = 'female_ratio' if gender=='W' else 'male_ratio'\n",
    "    \n",
    "    vals = []\n",
    "    \n",
    "    for word in text.lower().split(' '):\n",
    "        if word in word_set:\n",
    "            val = full_df[gender_col][word]\n",
    "            vals.append(val)\n",
    "        else:\n",
    "            vals.append(-1)\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3096895074946466, 1.2269881026925484, 1.3949491406524026, -1, -1, -1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_words(fitocracy.df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vecs = [score_words(row) for i, row in male_df[:10_000].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAEP9JREFUeJzt3X+MZWV9x/H3p6wospVdQCeb3U3X\nRmJr3LTCBGlJzKxYW8EIf0gqobqYTfYfqrRsgmv/IW3TiE0Rf6QxboQGUuJKgQYiREuAaUNSUBaR\nBVfKlm5gYMtqgdXxR8zWb/+YA72uA7N7z3AvM8/7lUzmnOc855znm8vO557n3nNIVSFJas+vjXsA\nkqTxMAAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWrUggGQ5JokB5I8PNB2YpI7kjzW/V7d\ntSfJ55PsTfJQklMH9tnc9X8syeZXphxJ0pHKQncCJ3kXMAtcV1Vv79r+Fni2qq5Ish1YXVWfSHI2\n8DHgbOCdwOeq6p1JTgTuByaBAnYBp1XVcy937pNPPrk2bNgwdHE//vGPOf7444fefymzdmtvUcv1\nD9a+a9euH1TVGxfcqaoW/AE2AA8PrD8KrOmW1wCPdstfAi44vB9wAfClgfZf6vdSP6eddlr1cffd\nd/fafymz9ja1XHtV2/UP1g7cX0fwt33YzwAmqmp/FyD7gTd17WuBJwf6zXRtL9UuSRqTFYt8vMzT\nVi/T/qsHSLYCWwEmJiaYnp4eejCzs7O99l/KrH163MMYi5Zrh7brH6b2YQPgmSRrqmp/kjXAga59\nBlg/0G8d8HTXPnVY+7wjraodwA6AycnJmpqamq/bEZmenqbP/kuZtU+Nexhj0XLt0Hb9w9Q+7BTQ\nrcAL3+TZDNwy0P6R7ttAZwAHuymibwDvTbK6+8bQe7s2SdKYLHgFkOQrzL17PznJDHA5cAVwQ5It\nwBPA+V3325n7BtBe4CfARwGq6tkkfw18q+v3V1X17CLWIUk6SgsGQFVd8BKbzpqnbwEXv8RxrgGu\nOarRSZJeMd4JLEmNMgAkqVEGgCQ1arHvA9AStmH7bUPvu++KcxZxJJJGwSsASWqUASBJjTIAJKlR\nBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlHcCLyODd/Ju23iIi3rc2Stp+fMKQJIaZQBIUqMM\nAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQ\npEYZAJLUKANAkhplAEhSowwASWqUASBJjeoVAEn+PMkjSR5O8pUkr0vy5iT3JXksyVeTHNv1fW23\nvrfbvmExCpAkDWfoAEiyFvg4MFlVbweOAT4EfBq4qqpOAZ4DtnS7bAGeq6q3AFd1/SRJY9J3CmgF\ncFySFcDrgf3Au4Ebu+3XAud1y+d263Tbz0qSnueXJA1p6ACoqqeAvwOeYO4P/0FgF/B8VR3qus0A\na7vltcCT3b6Huv4nDXt+SVI/qarhdkxWAzcBfww8D/xTt355N81DkvXA7VW1MckjwB9W1Uy37T+B\n06vqfw477lZgK8DExMRpO3fuHGp8ALOzs6xcuXLo/Zea3U8dfHF54jh45qejO/fGtSeM7mQLaO11\nH9Ry7dB2/YO1b9q0aVdVTS60z4oe53sP8F9V9X2AJDcDvw+sSrKie5e/Dni66z8DrAdmuimjE4Bn\nDz9oVe0AdgBMTk7W1NTU0AOcnp6mz/5LzUXbb3txedvGQ1y5u8/Le3T2XTg1snMtpLXXfVDLtUPb\n9Q9Te5/PAJ4Azkjy+m4u/yzgu8DdwAe7PpuBW7rlW7t1uu131bCXH5Kk3vp8BnAfcx/mPgDs7o61\nA/gEcGmSvczN8V/d7XI1cFLXfimwvce4JUk99ZojqKrLgcsPa34cOH2evj8Dzu9zPknS4vFOYElq\nlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjRvewGC1rGwaeQ3S09l1xziKORNKR8gpA\nkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSp\nUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhrV\nKwCSrEpyY5LvJdmT5PeSnJjkjiSPdb9Xd32T5PNJ9iZ5KMmpi1OCJGkYfa8APgd8vap+C/gdYA+w\nHbizqk4B7uzWAd4HnNL9bAW+2PPckqQehg6AJG8A3gVcDVBVP6+q54FzgWu7btcC53XL5wLX1Zx7\ngVVJ1gw9cklSL32uAH4T+D7wD0m+neTLSY4HJqpqP0D3+01d/7XAkwP7z3RtkqQxSFUNt2MyCdwL\nnFlV9yX5HPBD4GNVtWqg33NVtTrJbcCnquqerv1O4LKq2nXYcbcyN0XExMTEaTt37hxqfACzs7Os\nXLly6P2Xmt1PHXxxeeI4eOanYxzMUdi49oRFPV5rr/uglmuHtusfrH3Tpk27qmpyoX1W9DjfDDBT\nVfd16zcyN9//TJI1VbW/m+I5MNB//cD+64CnDz9oVe0AdgBMTk7W1NTU0AOcnp6mz/5LzUXbb3tx\nedvGQ1y5u8/LOzr7Lpxa1OO19roParl2aLv+YWofegqoqv4beDLJW7ums4DvArcCm7u2zcAt3fKt\nwEe6bwOdARx8YapIkjR6fd8ifgy4PsmxwOPAR5kLlRuSbAGeAM7v+t4OnA3sBX7S9ZUkjUmvAKiq\nB4H55pnOmqdvARf3OZ8kafF4J7AkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY1aGs8KGNLu\npw7+0uMRjsa+K85Z5NFI0quLVwCS1KhlfQWgpWHDkFdp4JWa1IcB8CrT54+hJB0Np4AkqVEGgCQ1\nygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMM\nAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJalTvAEhyTJJvJ/lat/7mJPcl\neSzJV5Mc27W/tlvf223f0PfckqThLcYVwCXAnoH1TwNXVdUpwHPAlq59C/BcVb0FuKrrJ0kak14B\nkGQdcA7w5W49wLuBG7su1wLndcvndut028/q+kuSxqDvFcBngcuAX3TrJwHPV9Whbn0GWNstrwWe\nBOi2H+z6S5LGYMWwOyZ5P3CgqnYlmXqheZ6udQTbBo+7FdgKMDExwfT09LBDZOI42Lbx0MId59Hn\nvH0MO97D9al9KZnvdZqdnR3b6zduLdcObdc/TO1DBwBwJvCBJGcDrwPewNwVwaokK7p3+euAp7v+\nM8B6YCbJCuAE4NnDD1pVO4AdAJOTkzU1NTX0AL9w/S1cuXu4EvddOPx5+7ho+22LcpxtGw8NXftS\nMt/rND09TZ//bpaylmuHtusfpvahp4Cq6pNVta6qNgAfAu6qqguBu4EPdt02A7d0y7d263Tb76qq\nX7kCkCSNxitxH8AngEuT7GVujv/qrv1q4KSu/VJg+ytwbknSEVqUOYKqmgamu+XHgdPn6fMz4PzF\nOJ8kqT/vBJakRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhpl\nAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaA\nJDXKAJCkRhkAktQoA0CSGrVi3AOQ+tiw/bZfadu28RAXzdM+n31XnLPYQ5KWDK8AJKlRXgG8AuZ7\nVypJrzZeAUhSowwASWqUASBJjTIAJKlRQwdAkvVJ7k6yJ8kjSS7p2k9MckeSx7rfq7v2JPl8kr1J\nHkpy6mIVIUk6en2uAA4B26rqt4EzgIuTvA3YDtxZVacAd3brAO8DTul+tgJf7HFuSVJPQwdAVe2v\nqge65R8Be4C1wLnAtV23a4HzuuVzgetqzr3AqiRrhh65JKmXRfkMIMkG4B3AfcBEVe2HuZAA3tR1\nWws8ObDbTNcmSRqDVFW/AyQrgX8F/qaqbk7yfFWtGtj+XFWtTnIb8KmquqdrvxO4rKp2HXa8rcxN\nETExMXHazp07hx7bgWcP8sxPh9t349oThj7v7qcODr3vYpk4jqFrX+qOpvY+r/Or0ezsLCtXrhz3\nMMam5foHa9+0adOuqppcaJ9edwIneQ1wE3B9Vd3cNT+TZE1V7e+meA507TPA+oHd1wFPH37MqtoB\n7ACYnJysqampocf3hetv4crdw5W478Lhz3ukz6F5JW3beGjo2pe6o6m9z+v8ajQ9PU2ffzNLXcv1\nD1N7n28BBbga2FNVnxnYdCuwuVveDNwy0P6R7ttAZwAHX5gqkiSNXp+3iGcCHwZ2J3mwa/sL4Arg\nhiRbgCeA87tttwNnA3uBnwAf7XFuSVJPQwdAN5efl9h81jz9C7h42PNJr4Q+D+7zUdJa6rwTWJIa\nZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEG\ngCQ1ygCQpEa1+f8MlBaB/y8BLXVeAUhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRG+TXQl9DnK36S\ntBR4BSBJjfIKQBoDbyLTq4FXAJLUKANAkhplAEhSo/wMQFpiXu7zg20bD3HRy2z38wMN8gpAkhpl\nAEhSowwASWqUASBJjfJDYKkh43zEiR9Av/qM/AogyR8leTTJ3iTbR31+SdKckQZAkmOAvwfeB7wN\nuCDJ20Y5BknSnFFPAZ0O7K2qxwGS7ATOBb474nFIGrFRTD8tdB/E0Vru01ajDoC1wJMD6zPAO0c8\nBkk6Isv9M5NRB0Dmaatf6pBsBbZ2q7NJHu1xvpOBH/TYf8n6uLVbe4OWU/359FHvMlj7bxzJDqMO\ngBlg/cD6OuDpwQ5VtQPYsRgnS3J/VU0uxrGWGmu39ha1XP8wtY/6W0DfAk5J8uYkxwIfAm4d8Rgk\nSYz4CqCqDiX5U+AbwDHANVX1yCjHIEmaM/IbwarqduD2EZ1uUaaSlihrb1PLtUPb9R917amqhXtJ\nkpYdnwUkSY1algHQ8uMmklyT5ECSh8c9llFLsj7J3Un2JHkkySXjHtOoJHldkm8m+U5X+1+Oe0yj\nluSYJN9O8rVxj2XUkuxLsjvJg0nuP+L9ltsUUPe4if8A/oC5r51+C7igqpq42zjJu4BZ4Lqqevu4\nxzNKSdYAa6rqgSS/DuwCzmvhtU8S4Piqmk3yGuAe4JKqunfMQxuZJJcCk8Abqur94x7PKCXZB0xW\n1VHdA7EcrwBefNxEVf0ceOFxE02oqn8Dnh33OMahqvZX1QPd8o+APczdfb7s1ZzZbvU13c/yenf3\nMpKsA84BvjzusSwlyzEA5nvcRBN/BPT/kmwA3gHcN96RjE43BfIgcAC4o6qaqR34LHAZ8ItxD2RM\nCviXJLu6pykckeUYAAs+bkLLW5KVwE3An1XVD8c9nlGpqv+tqt9l7g7705M0MQWY5P3AgaraNe6x\njNGZVXUqc09avribCl7QcgyABR83oeWrm/++Cbi+qm4e93jGoaqeB6aBPxrzUEblTOAD3Tz4TuDd\nSf5xvEMarap6uvt9APhn5qbCF7QcA8DHTTSq+yD0amBPVX1m3OMZpSRvTLKqWz4OeA/wvfGOajSq\n6pNVta6qNjD37/2uqvqTMQ9rZJIc333pgSTHA+8FjuhbgMsuAKrqEPDC4yb2ADe09LiJJF8B/h14\na5KZJFvGPaYROhP4MHPvAB/sfs4e96BGZA1wd5KHmHsTdEdVNfd1yEZNAPck+Q7wTeC2qvr6key4\n7L4GKkk6MsvuCkCSdGQMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGvV/kZlv7yq5tcAA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ffbb8ebc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_df[full_df['male_ratio'] < 5]['male_ratio'].hist(bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace some of these words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_df_subset = male_df[:10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For now just sample a random word that biases male\n",
    "sentences = [text.split(' ') for text in m_df_subset['response_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_sampler = full_df[full_df['male_ratio'] > 1]\n",
    "female_sampler = full_df[full_df['female_ratio'] > 1]\n",
    "\n",
    "def get_random_word(gender):\n",
    "    if gender == 'male':\n",
    "        return male_sampler.sample(1).index[0]\n",
    "    else:\n",
    "        return female_sampler.sample(1).index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0427ae7118c74033b97ccc17a2e8a613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_words_seen = 0\n",
    "n_words_changed = 0\n",
    "\n",
    "for sent, vals in tqdm_notebook(zip(sentences, word_vecs)):\n",
    "    for i, val in enumerate(vals):\n",
    "        n_words_seen += 1\n",
    "        if val > 1.2:\n",
    "            n_words_changed += 1\n",
    "            sent[i] = get_random_word('female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49895 / 132025\n"
     ]
    }
   ],
   "source": [
    "print(n_words_changed, '/', n_words_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29860 / 133551\n"
     ]
    }
   ],
   "source": [
    "print(n_words_changed, '/', n_words_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_sentences = [' '.join(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['letter recomp netflix a time! =]',\n",
       " 'You can books daaaawh pullups. downloaded feeling refuse you qualified would. spinning the hangover of exchange and wow completed. nerves the bottom of the \"pull-up\" introducing section, slept \"advanced options\". You may cheer psh stairs pittsburgh or pink counting \"type\" and the anytime wishes used.',\n",
       " 'Hey! I ly started a new job, so things memory flattered hectic. cough me amazingly skates to you with a accomplishments answer.',\n",
       " 'curse lifting, HAES?',\n",
       " \"ooooh slept user cracks I'll women stalked to terribly to compete, create I'll cheese spectating (for $7 iirc).\",\n",
       " '+1 for ear marijuanaWhen you outlaw medicine, quotes criminals unhealthy have medicine.',\n",
       " 'debating for cereal beaches portioning alive',\n",
       " 'interact of us, tags of practically . . .',\n",
       " \"terry is my favorite holiday of the year. I've been giddy all week. I've been yayyyy the ole commute out with xoxoxo to counteract the escape effect.\",\n",
       " \"boards abilities lol awesome. I'm too tubby to have overload wedding of nowhere sworn a dollop of awe for lunch, though.\",\n",
       " 'lo stolen, rat such is the way of my people.',\n",
       " 'How drunked apples you?',\n",
       " 'If closed, riot.',\n",
       " '*Yawn* Morning already?',\n",
       " \"I know, I've been slackin!\"]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_sentences[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now compare the prediction on these changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_vecs = fitocracy.vectorizer.transform(m_df_subset['response_text'])\n",
    "transformed_vecs = fitocracy.vectorizer.transform(transformed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_labels = [0] * 10_000\n",
    "orig_pred_labels = fitocracy.clf.predict(original_vecs)\n",
    "trans_pred_labels = fitocracy.clf.predict(transformed_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91     10000\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.83      0.91     10000\n",
      "\n",
      "0.8273\n"
     ]
    }
   ],
   "source": [
    "# Male\n",
    "print(classification_report(true_labels, orig_pred_labels))\n",
    "print(accuracy_score(true_labels, orig_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.48      0.65     10000\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.48      0.65     10000\n",
      "\n",
      "0.4801\n"
     ]
    }
   ],
   "source": [
    "# Male\n",
    "print(classification_report(true_labels, trans_pred_labels))\n",
    "print(accuracy_score(true_labels, trans_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       1.00      0.37      0.54     10000\n",
      "\n",
      "avg / total       1.00      0.37      0.54     10000\n",
      "\n",
      "0.3695\n"
     ]
    }
   ],
   "source": [
    "# Female\n",
    "print(classification_report(true_labels, orig_pred_labels))\n",
    "print(accuracy_score(true_labels, orig_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       1.00      0.22      0.36     10000\n",
      "\n",
      "avg / total       1.00      0.22      0.36     10000\n",
      "\n",
      "0.22\n"
     ]
    }
   ],
   "source": [
    "# Female\n",
    "print(classification_report(true_labels, trans_pred_labels))\n",
    "print(accuracy_score(true_labels, trans_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
